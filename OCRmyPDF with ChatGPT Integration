# Step 1: Install Required Packages
!apt-get install -y ocrmypdf
!pip install openai
!pip install tqdm
!pip install nltk

# Step 2: Import Libraries
import sys
import openai
import pytesseract
import pymupdf as fitz  # PyMuPDF
import os
import io
from PIL import Image
from google.colab import files
import subprocess
import shutil
from google.colab import drive
import cv2
import numpy as np
from tqdm.notebook import tqdm
from multiprocessing import Pool
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize
import re

# Step 3: Set up OpenAI API key
openai.api_key = "YOUR_API_KEY_HERE"

# Step 4: Mount Google Drive
drive.mount('/content/drive')

# Step 5: Upload PDF files from your local machine
uploaded = files.upload()

# Function to preprocess the image for better OCR accuracy
def preprocess_image(image, apply_contrast=False, apply_denoising=False, apply_morphology=False):
    if len(image.shape) == 3:  # Convert to grayscale if the image is in color
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    if apply_contrast:
        gray = cv2.equalizeHist(gray)  # Contrast enhancement

    if apply_denoising:
        gray = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)  # Apply denoising

    if apply_morphology:
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        gray = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)  # Apply morphological transformations

    return gray

# Function to post-process extracted text
def post_process_text(text):
    # Remove unnecessary line breaks
    text = re.sub(r'(?<!\n)\n(?!\n)', ' ', text)
    # Remove non-printable characters
    text = ''.join(c for c in text if c.isprintable())
    # Remove hyphens at line breaks
    text = re.sub(r'-\s*\n', '', text)
    return text

# Function to process a single PDF
def process_pdf(uploaded_filename):
    print(f"Processing file: {uploaded_filename}")
    oct_output_filename = f"ocr_{uploaded_filename}"
    try:
        print(f"Starting OCR on file: {uploaded_filename}")
        result = subprocess.run(
            [
                "ocrmypdf",
                "-l", "eng",
                uploaded_filename,
                oct_output_filename
            ],
            check=True,
            text=True,
            capture_output=True
        )
        print(f"OCR completed successfully for file: {uploaded_filename}")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running OCRmyPDF: {e.stderr.decode('utf-8') if e.stderr else 'Unknown error'}")
        return

    # Step 7: Calculate OCR Confidence and Extract Text using pytesseract
    try:
        print(f"Opening OCR output PDF: {oct_output_filename}")
        pdf_document = fitz.open(oct_output_filename)
        extracted_text = ""
        avg_confidence = 0
        for page_num in tqdm(range(len(pdf_document)), desc=f"Extracting text from {uploaded_filename}", file=sys.stdout):
            print(f"Processing page {page_num + 1} of {len(pdf_document)}")
            page = pdf_document.load_page(page_num)
            pix = page.get_pixmap()
            img = Image.open(io.BytesIO(pix.tobytes('png')))

            # Convert to OpenCV format and preprocess
            open_cv_image = np.array(img)
            if len(open_cv_image.shape) == 3:
                open_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)

            # Iterative Preprocessing to Improve Confidence
            confidence_scores = []
            max_confidence = 0
            best_preprocessed_image = open_cv_image

            # Try different preprocessing combinations
            preprocessing_combinations = [
                {},
                {'apply_contrast': True},
                {'apply_denoising': True},
                {'apply_contrast': True, 'apply_denoising': True},
                {'apply_morphology': True},
                {'apply_contrast': True, 'apply_morphology': True},
                {'apply_denoising': True, 'apply_morphology': True},
                {'apply_contrast': True, 'apply_denoising': True, 'apply_morphology': True}
            ]

            for combination in preprocessing_combinations:
                preprocessed_image = preprocess_image(open_cv_image, **combination)
                img = Image.fromarray(preprocessed_image)

                data = pytesseract.image_to_data(img, config='--psm 3', output_type=pytesseract.Output.DICT)
                confidence_scores = [int(conf) for conf in data['conf'] if conf != -1]
                avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
                print(f"Confidence score for preprocessing {combination} on page {page_num + 1}: {avg_confidence}")

                if avg_confidence > max_confidence:
                    max_confidence = avg_confidence
                    best_preprocessed_image = preprocessed_image

            # Use the best preprocessed image for OCR
            img = Image.fromarray(best_preprocessed_image)
            page_text = pytesseract.image_to_string(img, config='--psm 3')
            extracted_text += page_text + "\n"
            print(f"Final average confidence score for page {page_num + 1}: {max_confidence}")
        pdf_document.close()
    except Exception as e:
        print(f"Error occurred while extracting text from OCR output: {e}")
        return

    # Step 8: Post-process the extracted text
    extracted_text = post_process_text(extracted_text)

    # Check if the extracted text is meaningful
    if len(extracted_text.strip()) == 0:
        print("No meaningful text extracted. Skipping ChatGPT review.")
        return

    # Step 9: Use ChatGPT to Review and Correct the Extracted Text
    try:
        print("Sending extracted text to ChatGPT for review...")
        # Split the extracted text into logical divisions (by paragraphs)
        paragraphs = extracted_text.split('\n\n')
        text_chunks = []
        current_chunk = ""

        # Build chunks of paragraphs
        for paragraph in paragraphs:
            if len(current_chunk) + len(paragraph) <= 2000:
                current_chunk += paragraph + "\n\n"
            else:
                if len(paragraph) < 10:  # Merge small paragraphs with the current chunk
                    current_chunk += paragraph + "\n\n"
                else:
                    text_chunks.append(current_chunk.strip())
                    current_chunk = paragraph + "\n\n"

        if current_chunk:
            text_chunks.append(current_chunk.strip())

        reviewed_text = ""
        for chunk in tqdm(text_chunks, desc="Reviewing text with ChatGPT", file=sys.stdout):
            # Print extracted OCR text before sending to ChatGPT
            print(f"Extracted OCR Text: {chunk[:500]}...")

            # Check if the chunk is meaningful before sending to ChatGPT
            if len(chunk.strip()) == 0:
                print("Skipping empty or non-meaningful chunk.")
                continue

            print(f"Reviewing chunk with ChatGPT: {chunk[:50]}...")
            retry_attempts = 3
            for attempt in range(retry_attempts):
                try:
                    response = openai.ChatCompletion.create(
                        model="gpt-4",
                        messages=[
                            {
                                "role": "system",
                                "content": (
                                    "You are a helpful assistant who checks and corrects OCR text. "
                                    "Please review and correct the following OCR text. Specifically:\n"
                                    "1. Correct grammar, punctuation, and spelling errors.\n"
                                    "2. Improve readability by reformatting sentences and paragraphs.\n"
                                    "3. Correct issues like inconsistent capitalization, missing spaces, or unnecessary line breaks.\n"
                                    "4. If the text is unclear, make a best-effort guess or mark it as '[unrecognizable]'.\n"
                                    "5. Remove any OCR-specific artifacts such as symbols that do not fit the context.\n"
                                    "If the text is unclear, please make a best effort to reconstruct it."
                                )
                            },
                            {
                                "role": "user",
                                "content": f"Please review and correct the following OCR text:\n{chunk}"
                            }
                        ]
)
                    print(f"ChatGPT Response for chunk: {response['choices'][0]['message']['content'][:50]}...")
                    reviewed_chunk = response['choices'][0]['message']['content']
                    print(f"Reviewed Chunk: {reviewed_chunk[:50]}...")
                    if reviewed_chunk.strip() == chunk.strip():
                        print("No changes made by ChatGPT for this chunk.")
                    reviewed_text += reviewed_chunk + "\n"
                    break
                except Exception as e:
                    if attempt < retry_attempts - 1:
                        print(f"Attempt {attempt + 1} failed. Retrying...")
                    else:
                        print(f"All retry attempts failed for this chunk: {e}")
        print("Review completed by ChatGPT.")
    except Exception as e:
        print(f"Error occurred while communicating with ChatGPT: {e}")
        return

    # Step 10: Compare Original OCR Text and ChatGPT's Corrected Version
    try:
        print("Comparing original OCR text with ChatGPT's corrected version...")
        original_lines = extracted_text.splitlines()
        reviewed_lines = reviewed_text.splitlines()
        updated_text = ""

        for orig, review in zip(original_lines, reviewed_lines):
            if orig.strip() != review.strip():
                print(f"Line modified: Original: '{orig[:50]}...' -> Reviewed: '{review[:50]}...'")
                updated_text += review + "\n"
            else:
                updated_text += orig + "\n"

        print("Comparison completed.")
    except Exception as e:
        print(f"Error occurred during comparison: {e}")
        return

    # Step 11: Create Updated OCR PDF
    updated_txt_filename = f"updated_{uploaded_filename}.txt"
    with open(updated_txt_filename, "w") as text_file:
        text_file.write(updated_text)
    print(f"Updated text file created: {updated_txt_filename}")

    updated_pdf_filename = f"updated_{uploaded_filename}"
    try:
        print(f"Creating updated OCR PDF: {updated_pdf_filename}")
        result = subprocess.run(
            [
                "ocrmypdf",
                "-l", "eng",
                "--sidecar", updated_txt_filename,
                uploaded_filename,
                updated_pdf_filename
            ],
            check=True,
            text=True,
            capture_output=True
        )
        print(f"Updated OCR PDF created successfully: {updated_pdf_filename}")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while creating updated OCR PDF: {e.stderr.decode('utf-8') if e.stderr else 'Unknown error'}")
        return

    # Step 12: Save Updated PDF to Google Drive and Provide Link
    output_drive_path = f"/content/drive/MyDrive/OCR_Scanned_PDFs/{updated_pdf_filename}"
    print(f"Saving updated OCR output to Google Drive: {output_drive_path}")
    os.makedirs(os.path.dirname(output_drive_path), exist_ok=True)
    if os.path.exists(output_drive_path):
        os.remove(output_drive_path)  # Remove the existing file if it already exists
    shutil.move(updated_pdf_filename, output_drive_path)

    if os.path.exists(output_drive_path):
        print(f"Updated OCR output saved successfully: {output_drive_path}")
        print(f"You can access the updated file here: {output_drive_path}")
    else:
        print(f"File {output_drive_path} was not created. Please check the OCR process for issues.")

# Step 13: Use multiprocessing to process PDFs in parallel
with Pool() as pool:
    pool.map(process_pdf, uploaded.keys())
